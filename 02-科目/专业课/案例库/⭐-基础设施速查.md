---
title: ⭐ AI 基础设施速查
subject: 专业课843
type: 速查表
created: 2026-02-27
tags: [案例库, 843, 速查, 基础设施, 向量数据库, 算力]
---

# ⭐ AI 基础设施速查

> 了解定位即可 | 这层是 AI 应用的"水电煤"——843 考试中了解分层即可

---

## AI 基础设施分层图

```
应用层：ChatGPT / Cursor / Harvey / Notion AI
  ↑ 调用
模型层：OpenAI / Anthropic / Mistral / DeepSeek
  ↑ 需要
算力层：CoreWeave / RunPod / Lambda（GPU 租赁）
  ↑ 辅助
推理加速：Groq（LPU）/ Together AI / Fireworks
  ↑ 数据管理
向量存储：Pinecone / Weaviate / Chroma / Qdrant
  ↑ 模型托管
开源社区：Hugging Face / Replicate
```

---

## 三、基础模型平台（⭐）

| 产品 | 一句话定位 | 记忆点 |
|------|-----------|--------|
| **Cohere** | 企业级文本 AI API | 专注 NLP 任务（搜索/分类/生成），面向 B2B 企业集成，不做消费端产品 |
| **Groq** | 超快推理芯片（LPU） | 自研 LPU（语言处理单元）推理速度比 GPU 快 10×+，专为 LLM 推理优化；速度是核心卖点 |
| **Together AI** | 开源模型托管平台 | 一个 API 访问所有主流开源模型（Llama/Mistral/Qwen），按 token 计费 |
| **Fireworks** | 快速推理服务 | 专注低延迟推理，面向需要实时响应的 AI 应用（游戏/对话等）|

---

## 四、推理与算力平台（⭐）

| 产品 | 一句话定位 | 记忆点 |
|------|-----------|--------|
| **RunPod** | GPU 云租赁（按小时）| AI 时代的"GPU 共享单车"，个人/初创可按需租 A100/H100，比 AWS 便宜 |
| **Modal** | 无服务器 GPU 计算 | 写 Python 函数直接在 GPU 上运行，无需配置服务器；Serverless AI 计算的代表 |
| **Lambda** | GPU 云服务 | 专为深度学习定制的云平台，比通用云（AWS/GCP）便宜且专业 |
| **Baseten** | 模型部署平台 | 把 Hugging Face 模型一键部署为生产 API，简化 MLOps 流程 |
| **OctoAI** | 开源模型优化部署 | 自动优化模型（量化/蒸馏）后部署，降低推理成本 |
| **CoreWeave** | GPU 基础设施云 | 专业 GPU 云，OpenAI 等顶级 AI 公司的算力供应商，HPC 级别 |
| **Crusoe** | 清洁能源 GPU 算力 | 用油田伴生气（本会燃烧的废气）发电供 GPU，ESG + 低成本双卖点 |

---

## 五、向量数据库与 RAG 基础设施（⭐）

**选择向量数据库的决策树：**
```
需要全托管？
  是 → Pinecone（⭐⭐，最流行）
  否 → 开源自部署
         ├── 需要高性能？→ Qdrant（Rust，最快）
         ├── 已有 PostgreSQL？→ Supabase Vector（pgvector）
         ├── 需要多模态？→ Weaviate / LanceDB
         ├── 已有 MongoDB？→ MongoDB Atlas Vector
         └── 超大规模？→ Milvus / Vespa
```

| 产品 | 一句话定位 | 记忆点 |
|------|-----------|--------|
| **Weaviate** | 开源向量数据库 | 支持多模态（文字+图像向量），内置 GraphQL API，自带向量化模块 |
| **Chroma** | 轻量嵌入式向量存储 | 开发原型首选，pip 安装即用，无需独立服务；生产环境能力有限 |
| **Qdrant** | Rust 向量数据库 | 性能最强的开源向量数据库，过滤搜索能力强，适合生产部署 |
| **Milvus** | 开源分布式向量数据库 | 处理十亿级向量，大规模生产场景首选，Zilliz 商业版 |
| **Supabase Vector** | PostgreSQL + pgvector | 已有 Supabase 项目可直接开启，SQL 操作向量，降低学习成本 |
| **LanceDB** | 多模态向量存储 | 支持图像/文本/音频混合存储，本地文件格式（无需服务器）|
| **Elastic** | 混合检索（向量+关键词）| 传统搜索引擎加入向量能力，BM25 + 语义搜索混合，企业搜索改造 |
| **MongoDB Atlas Vector** | 文档数据库集成向量搜索 | 已有 MongoDB 的团队无需迁移，直接在文档里存向量 |
| **Vespa** | 大规模向量+结构化搜索 | Yahoo 出品，支持实时更新+大规模，广告/推荐系统场景 |

---

## 843 考试记忆要点

**技术层次答题框架（最有用）：**

> 任何 AI 应用产品的背后都有一套基础设施支撑：**算力层**（GPU云）→ **模型层**（大模型API）→ **数据层**（向量数据库+RAG）→ **应用层**。这种分层结构类似互联网时代的"IaaS→PaaS→SaaS"，AI 正在重复这个基础设施化的过程。

**重点记 3 个代表性产品：**
- **Groq**：LPU 专用推理芯片，速度是核心差异化
- **Chroma**：开发原型用，极简上手
- **Qdrant**：生产部署用，性能最强
